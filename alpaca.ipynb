{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw27LlSxo96lQ1cfAkF7vV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nermal1/Stock-Market-Prediction/blob/main/alpaca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "4kUAxRvKGhjA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9w2dwyqiGZbU"
      },
      "outputs": [],
      "source": [
        "from alpaca.data.historical import StockHistoricalDataClient\n",
        "from alpaca.data.requests import StockBarsRequest\n",
        "from alpaca.data.timeframe import TimeFrame\n",
        "from alpaca.trading.client import TradingClient\n",
        "from alpaca.trading.enums import OrderSide, TimeInForce\n",
        "from alpaca.trading.requests import MarketOrderRequest\n",
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"PKYI39LXLT3K2SSXGBC7\"\n",
        "API_SECRET = \"yzpMAtY5CCLxq2azyBgony0fzZeYgznPqMfzU0sU\"\n",
        "\n",
        "data_client = StockHistoricalDataClient(API_KEY, API_SECRET)\n",
        "trading_client = TradingClient(API_KEY, API_SECRET, paper=True)"
      ],
      "metadata": {
        "id": "M-wlTaCLD-WC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = datetime.datetime(2020, 6, 1)\n",
        "end = datetime.datetime(2025, 7, 1)\n",
        "symbols = [\"JPM\", \"KULR\", \"META\", \"MS\", \"MU\", \"NVDA\", \"OKLO\", \"AVGO\"]"
      ],
      "metadata": {
        "id": "v8VdaNBWFQ27"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "account = trading_client.get_account()\n",
        "available_cash = float(account.cash)\n",
        "\n",
        "positions = trading_client.get_all_positions()\n",
        "held_symbols = {pos.symbol for pos in positions}\n"
      ],
      "metadata": {
        "id": "QStGCUylGy07"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "request_params = StockBarsRequest(\n",
        "    symbol_or_symbols=symbols,\n",
        "    timeframe=TimeFrame.Day,\n",
        "    start=start,\n",
        "    end=end\n",
        ")\n",
        "bars = data_client.get_stock_bars(request_params).df"
      ],
      "metadata": {
        "id": "AJVnopocFUe8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbol_dfs = {}\n",
        "for symbol in symbols:\n",
        "    symbol_df = bars.loc[bars.index.get_level_values('symbol') == symbol, ['close']]\n",
        "    symbol_df.rename(columns={'close': 'Close'}, inplace=True)\n",
        "    symbol_dfs[symbol] = symbol_df"
      ],
      "metadata": {
        "id": "NSOY35VmFmLP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df, window_size=60):\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled = scaler.fit_transform(df)\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(window_size, len(scaled)):\n",
        "        X.append(scaled[i - window_size:i, 0])\n",
        "        y.append(scaled[i, 0])\n",
        "\n",
        "    X = np.array(X).reshape(-1, window_size, 1)\n",
        "    y = np.array(y)\n",
        "    return X, y, scaler"
      ],
      "metadata": {
        "id": "ur2vCEFiGDi5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(50, return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model"
      ],
      "metadata": {
        "id": "0DJufaRMH5zf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "models_dir = \"trained_models\"\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "# Train and save model per stock\n",
        "for symbol in symbols:\n",
        "    df = symbol_dfs[symbol]\n",
        "    if len(df) < 100:\n",
        "        print(f\"Skipping {symbol}, not enough data.\")\n",
        "        continue\n",
        "\n",
        "    X, y, scaler = preprocess_data(df)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(50, return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    print(f\"Training model for {symbol}\")\n",
        "    model.fit(X, y, epochs=20, batch_size=32, verbose=0)\n",
        "\n",
        "    # Save model\n",
        "    model.save(f\"{models_dir}/{symbol}_lstm_model.h5\")\n",
        "    print(f\"Saved model for {symbol}\")\n",
        "\n",
        "    # Save scaler too (optional but helpful for consistent predictions)\n",
        "    import joblib\n",
        "    joblib.dump(scaler, f\"{models_dir}/{symbol}_scaler.save\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmXt5M0NGSAA",
        "outputId": "bac82d80-4bd3-4e4f-cfd8-686270383ce2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model for JPM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model for JPM\n",
            "Training model for KULR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model for KULR\n",
            "Training model for META\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model for META\n",
            "Training model for MS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model for MS\n",
            "Training model for MU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model for MU\n",
            "Training model for NVDA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model for NVDA\n",
            "Training model for OKLO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model for OKLO\n",
            "Training model for AVGO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model for AVGO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_price(model, df, scaler, window_size=60):\n",
        "    X, _, _ = preprocess_data(df, window_size)\n",
        "    last_input = X[-1].reshape(1, window_size, 1)\n",
        "    pred_scaled = model.predict(last_input)\n",
        "    predicted_price = scaler.inverse_transform([[pred_scaled[0][0]]])[0][0]\n",
        "    last_price = df['Close'].iloc[-1]\n",
        "    return predicted_price, last_price"
      ],
      "metadata": {
        "id": "5o872puBGcij"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_signal(predicted, current, threshold=0.01):\n",
        "    change = (predicted - current) / current\n",
        "    if change > threshold:\n",
        "        return \"buy\"\n",
        "    elif change < -threshold:\n",
        "        return \"sell\"\n",
        "    return \"hold\""
      ],
      "metadata": {
        "id": "xyIGvqS5G4eJ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_trade(symbol, signal, current_price, held_symbols, available_cash):\n",
        "    if signal == \"buy\":\n",
        "        if symbol in held_symbols:\n",
        "            print(f\"Already holding {symbol}, skipping buy.\")\n",
        "            return\n",
        "        if available_cash < current_price:\n",
        "            print(f\"Not enough cash to buy {symbol}. Needed: ${current_price:.2f}, Available: ${available_cash:.2f}\")\n",
        "            return\n",
        "        order = MarketOrderRequest(\n",
        "            symbol=symbol,\n",
        "            qty=1,\n",
        "            side=OrderSide.BUY,\n",
        "            time_in_force=TimeInForce.DAY\n",
        "        )\n",
        "        trading_client.submit_order(order)\n",
        "        print(f\"BUY 1 share of {symbol} at ~${current_price:.2f}\")\n",
        "\n",
        "    elif signal == \"sell\":\n",
        "        if symbol not in held_symbols:\n",
        "            print(f\"No holdings to sell in {symbol}, skipping.\")\n",
        "            return\n",
        "        order = MarketOrderRequest(\n",
        "            symbol=symbol,\n",
        "            qty=1,\n",
        "            side=OrderSide.SELL,\n",
        "            time_in_force=TimeInForce.DAY\n",
        "        )\n",
        "        trading_client.submit_order(order)\n",
        "        print(f\"SELL 1 share of {symbol} at ~${current_price:.2f}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"HOLD {symbol}\")"
      ],
      "metadata": {
        "id": "FVutvy47G9nt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "account = trading_client.get_account()\n",
        "available_cash = float(account.cash)\n",
        "positions = trading_client.get_all_positions()\n",
        "held_symbols = {pos.symbol for pos in positions}\n",
        "\n",
        "window_size = 60\n",
        "\n",
        "for symbol in symbols:\n",
        "    df = symbol_dfs[symbol]\n",
        "    if len(df) < window_size + 1:\n",
        "        print(f\"Not enough data for {symbol}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        model = load_model(f\"trained_models/{symbol}_lstm_model.h5\")\n",
        "        scaler = joblib.load(f\"trained_models/{symbol}_scaler.save\")\n",
        "    except:\n",
        "        print(f\"No model or scaler found for {symbol}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    predicted, current = predict_next_price(model, df, scaler)\n",
        "    signal = generate_signal(predicted, current)\n",
        "    execute_trade(symbol, signal, current, held_symbols, available_cash)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kov-FrqbJb1R",
        "outputId": "cb1059c2-e900-4bab-99d2-84467540a60f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
            "No holdings to sell in JPM, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n",
            "No holdings to sell in KULR, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No holdings to sell in META, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78ddf199b2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No holdings to sell in MS, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78ddeea059e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BUY 1 share of MU at ~$123.25\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already holding NVDA, skipping buy.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No holdings to sell in OKLO, skipping.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
            "SELL 1 share of AVGO at ~$275.65\n"
          ]
        }
      ]
    }
  ]
}